id,ABSTRACT,Computer Science,Mathematics,Physics,Statistics,Analysis of PDEs,Applications,Artificial Intelligence,Astrophysics of Galaxies,Computation and Language,Computer Vision and Pattern Recognition,Cosmology and Nongalactic Astrophysics,Data Structures and Algorithms,Differential Geometry,Earth and Planetary Astrophysics,Fluid Dynamics,Information Theory,Instrumentation and Methods for Astrophysics,Machine Learning,Materials Science,Methodology,Number Theory,Optimization and Control,Representation Theory,Robotics,Social and Information Networks,Statistics Theory,Strongly Correlated Electrons,Superconductivity,Systems and Control
1824,"a ever-growing datasets inside observational astronomy have challenged scientists inside many aspects, including an efficient and interactive data exploration and visualization. many tools have been developed to confront this challenge. however, they usually focus on displaying a actual images or focus on visualizing patterns within catalogs inside the predefined way. inside this paper we introduce vizic, the python visualization library that builds a connection between images and catalogs through an interactive map of a sky region. vizic visualizes catalog data over the custom background canvas with the help of a shape, size and orientation of each object inside a catalog. a displayed objects inside a map are highly interactive and customizable comparing to those inside a images. these objects should be filtered by or colored by their properties, such as redshift and magnitude. they also should be sub-selected with the help of the lasso-like tool considering further analysis with the help of standard python functions from in the jupyter notebook. furthermore, vizic allows custom overlays to be appended dynamically on top of a sky map. we have initially implemented several overlays, namely, voronoi, delaunay, minimum spanning tree and healpix grid layers, which are helpful considering visualizing large-scale structure. all these overlays should be generated, added or removed interactively with one line of code. a catalog data was stored inside the non-relational database, and a interfaces were developed inside javascript and python to work within jupyter notebook, which allows to create custom widgets, user generated scripts to analyze and plot a data selected/displayed inside a interactive map. this unique design makes vizic the very powerful and flexible interactive analysis tool. vizic should be adopted inside variety of exercises, considering example, data inspection, clustering analysis, galaxy alignment studies, outlier identification or simply large-scale visualizations.",0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3094,"we propose the framework considering optimal $t$-matchings excluding a prescribed $t$-factors inside bipartite graphs. a proposed framework was the generalization of a nonbipartite matching problem and includes several problems, such as a triangle-free $2$-matching, square-free $2$-matching, even factor, and arborescence problems. inside this paper, we demonstrate the unified understanding of these problems by commonly extending previous important results. we solve our problem under the reasonable assumption, which was sufficiently broad to include a specific problems listed above. we first present the min-max theorem and the combinatorial algorithm considering a unweighted version. we then provide the linear programming formulation with dual integrality and the primal-dual algorithm considering a weighted version. the key ingredient of a proposed algorithm was the technique to shrink forbidden structures, which corresponds to a techniques of shrinking odd cycles, triangles, squares, and directed cycles inside edmonds' blossom algorithm, the triangle-free $2$-matching algorithm, the square-free $2$-matching algorithm, and an arborescence algorithm, respectively.",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
8463,"nanostructures with open shell transition metal or molecular constituents host often strong electronic correlations and are highly sensitive to atomistic material details. this tutorial review discusses method developments and applications of theoretical approaches considering a realistic description of a electronic and magnetic properties of nanostructures with correlated electrons. first, a implementation of the flexible interface between density functional theory and the variant of dynamical mean field theory (dmft) highly suitable considering a simulation of complex correlated structures was explained and illustrated. on a dmft side, this interface was largely based on recent developments of quantum monte carlo and exact diagonalization techniques allowing considering efficient descriptions of general four fermion coulomb interactions, reduced symmetries and spin-orbit coupling, which are explained here. with a examples of a cr (001) surfaces, magnetic adatoms, and molecular systems it was shown how a interplay of hubbard u and hund's j determines charge and spin fluctuations and how these interactions drive different sorts of correlation effects inside nanosystems. non-local interactions and correlations present the particular challenge considering a theory of low dimensional systems. we present our method developments addressing these two challenges, i.e., advancements of a dynamical vertex approximation and the combination of a constrained random phase approximation with continuum medium theories. we demonstrate how non-local interaction and correlation phenomena are controlled not only by dimensionality but also by coupling to a environment which was typically important considering determining a physics of nanosystems.",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
2082,"stars are self-gravitating fluids inside which pressure, buoyancy, rotation and magnetic fields provide a restoring forces considering global modes of oscillation. pressure and buoyancy energetically dominate, while rotation and magnetism are generally assumed to be weak perturbations and often ignored. however, observations of anomalously weak dipole mode amplitudes inside red giant stars suggest that the substantial fraction of these are subject to an additional source of damping localised to their core region, with indirect evidence pointing to a role of the deeply buried magnetic field. it was also known that inside many instances a gravity-mode character of affected modes was preserved, but so far no effective damping mechanism has been proposed that accommodates this aspect. here we present such the mechanism, which damps a oscillations of stars harbouring magnetised cores using resonant interactions with standing alfv√©n modes of high harmonic index. a damping rates produced by this mechanism are quantitatively on par with those associated with turbulent convection, and inside a range required to explain observations, considering realistic stellar models and magnetic field strengths. our results suggest that magnetic fields should provide an efficient means of damping stellar oscillations without needing to disrupt a internal structure of a modes, and lay a groundwork considering an extension of a theory of global stellar oscillations that incorporates these effects.",0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
8687,"deep neural perception and control networks are likely to be the key component of self-driving vehicles. these models need to be explainable - they should provide easy-to-interpret rationales considering their behavior - so that passengers, insurance companies, law enforcement, developers etc., should understand what triggered the particular behavior. here we explore a use of visual explanations. these explanations take a form of real-time highlighted regions of an image that causally influence a network's output (steering control). our idea behind the method was two-stage. inside a first stage, we use the visual attention model to train the convolution network end-to-end from images to steering angle. a attention model highlights image regions that potentially influence a network's output. some of these are true influences, but some are spurious. we then apply the causal filtering step to determine which input regions actually influence a output. this produces more succinct visual explanations and more accurately exposes a network's behavior. we demonstrate a effectiveness of our model on three datasets totaling 16 hours of driving. we first show that training with attention does not degrade a performance of a end-to-end network. then we show that a network causally cues on the variety of features that are used by humans while driving.",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
2342,"analyzing job hopping behavior was important considering understanding job preference and career progression of working individuals. when analyzed at a workforce population level, job hop analysis helps to gain insights of talent flow among different jobs and organizations. traditionally, surveys are conducted on job seekers and employers to study job hop behavior. beyond surveys, job hop behavior should also be studied inside the highly scalable and timely manner with the help of the data driven idea behind the method inside response to fast-changing job landscape. fortunately, a advent of online professional networks (opns) has made it possible to perform the large-scale analysis of talent flow. inside this paper, we present the new data analytics framework to analyze a talent flow patterns of close to 1 million working professionals from three different countries/regions with the help of their publicly-accessible profiles inside an established opn. as opn data are originally generated considering professional networking applications, our proposed framework re-purposes a same data considering the different analytics task. prior to performing job hop analysis, we devise the job title normalization procedure to mitigate a amount of noise inside a opn data. we then devise several metrics to measure a amount of work experience required to take up the job, to determine that existence duration of a job (also known as a job age), and a correlation between a above metric and propensity of hopping. we also study how job hop behavior was related to job promotion/demotion. lastly, we perform connectivity analysis at job and organization levels to derive insights on talent flow as well as job and organizational competitiveness.",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
16866,"a need to reason about uncertainty inside large, complex, and multi-modal datasets has become increasingly common across modern scientific environments. a ability to transform samples from one distribution $p$ to another distribution $q$ enables a solution to many problems inside machine learning (e.g. bayesian inference, generative modeling) and has been actively pursued from theoretical, computational, and application perspectives across a fields of information theory, computer science, and biology. performing such transformations, inside general, still leads to computational difficulties, especially inside high dimensions. here, we consider a problem of computing such ""measure transport maps"" with efficient and parallelizable methods. under a mild assumptions that $p$ need not be known but should be sampled from, and that a density of $q$ was known up to the proportionality constant, and that $q$ was log-concave, we provide inside this work the convex optimization problem pertaining to relative entropy minimization. we show how an empirical minimization formulation and polynomial chaos map parameterization should allow considering learning the transport map between $p$ and $q$ with distributed and scalable methods. we also leverage findings from nonequilibrium thermodynamics to represent a transport map as the composition of simpler maps, each of which was learned sequentially with the transport cost regularized version of a aforementioned problem formulation. we provide examples of our framework within a context of bayesian inference considering a boston housing dataset and generative modeling considering handwritten digit images from a mnist dataset.",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
11132,"period approximation was one of a central topics inside astronomical time series analysis, where data was often unevenly sampled. especially challenging are studies of stellar magnetic cycles, as there a periods looked considering are of a order of a same length than a datasets themselves. a datasets often contain trends, a origin of which was either the real long-term cycle or an instrumental effect, but these effects cannot be reliably separated, while they should lead to erroneous period determinations if not properly handled. inside this study we aim at developing the method that should handle a trends properly, and by performing extensive set of testing, we show that this was a optimal procedure when contrasted with methods that do not include a trend directly to a model. a effect of a form of a noise (whether constant or heteroscedastic) on a results was also investigated. we introduce the bayesian generalised lomb-scargle periodogram with trend (bglst), which was the probabilistic linear regression model with the help of gaussian priors considering a coefficients and uniform prior considering a frequency parameter. we show, with the help of synthetic data, that when there was no prior information on whether and to what extent a true model of a data contains the linear trend, a introduced bglst method was preferable to a methods which either detrend a data or leave a data untrended before fitting a periodic model. whether to use noise with different than constant variance inside a model depends on a density of a data sampling as well as on a true noise type of a process.",0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0
18709,"nowadays data compressors are applied to many problems of text analysis, but many such applications are developed outside of a framework of mathematical statistics. inside this paper we overcome this obstacle and show how several methods of classical mathematical statistics should be developed based on applications of a data compressors.",1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0